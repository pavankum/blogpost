{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aeffff0",
   "metadata": {},
   "source": [
    "# 1. Set up a persistent server for QCFractal\n",
    "\n",
    "Preferably a long running server instance is helpful, otherwise you can setup a server for a few days, run your calculations, backup the data and shudown the server and restart again from the backup. \n",
    "A sample slurmscript for a server job of two weeks looks like\n",
    "\n",
    "```\n",
    "#! /usr/bin/bash\n",
    "#SBATCH --partition=partition_name\n",
    "#SBATCH -t 14-00:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem-per-cpu=10gb\n",
    "#SBATCH --export ALL\n",
    "## USAGE\n",
    "\n",
    "#echo $(hostname) > hostfile\n",
    "source $HOME/.bashrc\n",
    "\n",
    "## All this script needs is qcfractal environment, so this conda env should work\n",
    "## https://github.com/openforcefield/qca-dataset-submission/blob/master/devtools/prod-envs/qcarchive-user-submit.yaml\n",
    "conda activate qcf-user-submit\n",
    "\n",
    "# these steps will initiate QCFractal server\n",
    "qcfractal-server init --base-folder \"/tmp/$SLURM_JOBID\" --max-active-services 300 --query-limit 100000\n",
    "\n",
    "qcfractal-server start --base-folder \"/tmp/$SLURM_JOBID\"\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "After initiating the server you can submit your collection of molecules using the following piece of python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd707bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcportal.client import FractalClient\n",
    "from openff.qcsubmit.datasets import load_dataset\n",
    "\n",
    "\n",
    "# load the dataset from file \n",
    "dataset = load_dataset(\"dataset.json.bz2\")\n",
    "\n",
    "# host name can be the node name, for example here it is hpc3-l18-03, and the default port is 7777 unless another port is specified during server inititation\n",
    "host_name_with_default_port = \"hpc3-l18-03:7777\"\n",
    "\n",
    "client = FractalClient(host_name_with_default_port, verify=False)\n",
    "\n",
    "submission = dataset.submit(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b1784",
   "metadata": {},
   "source": [
    "To run a local instance you can check an earlier blog post here, https://openforcefield.org/community/news/science-updates/ff-training-example-2021-07-01/, which uses\n",
    "```\n",
    "from qcfractal import FractalSnowflakeHandler\n",
    "from qcportal.client import FractalClient\n",
    "\n",
    "local_fractal_instance = FractalSnowflakeHandler(ncores=16)\n",
    "local_fractal_client = FractalClient(local_fractal_instance)\n",
    "submission = torsion_drive_dataset.submit(local_fractal_client)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada9a10",
   "metadata": {},
   "source": [
    "# 2. After submitting the dataset, the server will wait for workers to distribute the work to\n",
    "\n",
    "Workers can be spawned depending on the program in use with various program-specific conda environments located at our tested production environments at https://github.com/openforcefield/qca-dataset-submission/tree/master/devtools/prod-envs. \n",
    "\n",
    "\n",
    "A sample slurmscript for a Psi4 QM job which creates 5 workers with 8 cores each and 180GB distributed among the 5 workers. You can submit as many workers as you can that would speed up the computation since all the jobs would be distributed among the workers. The verbose slurm output would show the job success rate and if there is a high error rate managers can be stopped and failed job outputs can be inspected.\n",
    "\n",
    "\n",
    "    \n",
    "```\n",
    "#! /usr/bin/bash\n",
    "#SBATCH --partition=free\n",
    "#SBATCH -t 3-00:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=40\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=180gb\n",
    "#SBATCH --export ALL\n",
    "\n",
    "## USAGE\n",
    "#echo $(hostname) > hostfile\n",
    "source $HOME/.bashrc\n",
    "conda activate qcarchive-worker-openff-psi4\n",
    "#host=\"$(cat ./host)\"\n",
    "\n",
    "qcfractal-manager --verbose --fractal-uri \"hpc3-l18-03:7777\" --verify False --tasks-per-worker 5 --cores-per-worker 40 --memory-per-worker 180 --update-frequency 5\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Please make sure to use the right conda environment for the right program to spawn corresponding workers for a psi4 job, xtb job, openmm job or ANI job.\\\n",
    "### Also, the config can be supplied in an yaml file such as \n",
    "\n",
    "```\n",
    "common:\n",
    " adapter: pool\n",
    " max_workers: 5\n",
    " tasks_per_worker: 1\n",
    " cores_per_worker: 48\n",
    " memory_per_worker: 180\n",
    " retries: 5\n",
    " scratch_directory: /tmp/$SLURM_JOB_ID\n",
    "\n",
    "server:\n",
    " fractal_uri: hpc3-l18-03:7777\n",
    "\n",
    "manager:\n",
    " manager_name: local_server\n",
    " queue_tag:\n",
    "    - openff\n",
    " log_file_prefix: '../logs/$SLURM_JOB_ID.log'\n",
    " update_frequency: 30\n",
    " test: False\n",
    "\n",
    "```\n",
    "and it can be passed to qcfractal manager as \n",
    "```\n",
    "qcfractal-manager --verbose --config-file qm-config.${SLURM_JOBID}.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3d2bb7",
   "metadata": {},
   "source": [
    "# 3. Creating backup of the data\n",
    "\n",
    "A backup of the whole database with any number of collections can be created by using the following command on the host \n",
    "```\n",
    "qcfractal-server backup\n",
    "```\n",
    "This would create a `qcfractal_default.bak` file in the directory in which the command is executed. The backup can be read again in a restarted server instance by invoking\n",
    "```\n",
    "qcfractal-server restore\n",
    "```\n",
    "before starting the server but after initiating it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db267087",
   "metadata": {},
   "source": [
    "# 4. Error cycling\n",
    "\n",
    "It is common to encounter some failed calculations depending on the partition you're running (if you use pre-empitble queue jobs may get cancelled before completion), slurm configuration used (for some larger systems or basis sets you may run out of memory), or errors due to not reaching convergence, etc. Some of these failed jobs can be rerun after noticing what the error is, this can be done by the following piece of code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34eb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcportal.client import FractalClient\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "client = FractalClient()\n",
    "\n",
    "ds = client.get_collection(\"TorsionDriveDataset\", \"Biaryl Torsion Drives\")\n",
    "\n",
    "specs_list = list(ds.list_specifications().to_dict()['Description'].keys())\n",
    "\n",
    "status_dict = defaultdict(dict)\n",
    "indx = len(recs)\n",
    "num_complete = 0\n",
    "num_error = 0\n",
    "num_incomplete = 0\n",
    "num_running = 0\n",
    "num_nan = 0\n",
    "err_recs = []\n",
    "#Let's check for one specification from the list\n",
    "# For torsion scans the errored out jobs would be optimizations on the grid points,so we have to check the optimization history of a torsiondrive record and restart those errored out records\n",
    "spec = \"project_default\"\n",
    "for entry in ds.data.records.values():\n",
    "    td_rec = ds.get_record(entry.name, specification=spec)\n",
    "    optrecs_hist = []\n",
    "    for key, value in td_rec.dict()['optimization_history'].items():\n",
    "        if len(value) > 1:\n",
    "            print(key, value)\n",
    "            optrecs_hist.extend(td_rec.get_history(key))\n",
    "    for i, item in enumerate(optrecs_hist):\n",
    "        if item.status == 'COMPLETE':\n",
    "            num_complete += 1\n",
    "        elif item.status == 'ERROR':\n",
    "            err_recs.append(item.record.id)\n",
    "            # restart the failed calculations with this line\n",
    "            client.modify_tasks(operation='restart', base_result=item.record.id)\n",
    "            num_error += 1\n",
    "        elif item.status == 'INCOMPLETE':\n",
    "            num_incomplete += 1\n",
    "        elif item.status == 'RUNNING':\n",
    "            num_running += 1\n",
    "        else:\n",
    "            num_nan += 1\n",
    "\n",
    "status_dict['project_default'] = {\"COMPLETE\": num_complete, \"ERROR\": num_error, \"INCOMPLETE\": num_incomplete, \"RUNNING\": num_running, \"NaN\": num_nan}\n",
    "\n",
    "df = pd.DataFrame(status_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d5c24",
   "metadata": {},
   "source": [
    "## To look at the error codes of failed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "errored_manager = []\n",
    "error_types = []\n",
    "for err_rec in err_recs:\n",
    "    errored_manager.append(err_rec.manager_name.split('-')[0])\n",
    "    kv = client.query_kvstore(err_rec.error)\n",
    "    out = lzma.decompress(kv[list(kv.keys())[0]].data).decode()\n",
    "    print(\"-----------\")\n",
    "    error_typ = bytes(str(out), 'utf-8').decode(\"unicode_escape\")\n",
    "    error_types.append(error_typ)\n",
    "    print(error_typ, err_rec.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
